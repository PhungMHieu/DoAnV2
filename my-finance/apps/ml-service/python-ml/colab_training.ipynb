{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# My Finance - Category Classification Model\n## TF-IDF + SVM for Vietnamese Transaction Text\n\n**Cách upload file `training_data.json`:**\n1. Upload lên Google Drive\n2. Chạy cell mount Drive bên dưới\n3. Hoặc dùng URL nếu file đã public"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install scikit-learn pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === OPTION 1: Mount Google Drive (Recommended) ===\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Copy file từ Drive vào Colab\n# Thay đổi path phù hợp với vị trí file của bạn trên Drive\n!cp \"/content/drive/My Drive/training_data.json\" .\n\n# === OPTION 2: Direct upload (có thể lỗi với file lớn) ===\n# from google.colab import files\n# uploaded = files.upload()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing for Vietnamese\n",
    "TEENCODE_MAP = {\n",
    "    \"k\": \"không\", \"ko\": \"không\", \"k0\": \"không\",\n",
    "    \"dc\": \"được\", \"đc\": \"được\",\n",
    "    \"vs\": \"với\", \"j\": \"gì\", \"z\": \"vậy\", \"r\": \"rồi\",\n",
    "    \"cf\": \"cafe\", \"coffe\": \"coffee\", \"cofee\": \"coffee\",\n",
    "}\n",
    "\n",
    "TYPO_MAP = {\n",
    "    \"grap\": \"grab\", \"grabs\": \"grab\",\n",
    "    \"shoppee\": \"shopee\", \"lazda\": \"lazada\",\n",
    "    \"hoá đơn\": \"hóa đơn\", \"cà fê\": \"cà phê\",\n",
    "    \"ca phe\": \"cà phê\", \"tra sua\": \"trà sữa\",\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Normalize unicode\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Fix typos\n",
    "    for typo, fix in TYPO_MAP.items():\n",
    "        text = re.sub(re.escape(typo), fix, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Fix teencode\n",
    "    words = text.split()\n",
    "    words = [TEENCODE_MAP.get(w, w) for w in words]\n",
    "    text = \" \".join(words)\n",
    "    \n",
    "    # Remove special chars but keep Vietnamese\n",
    "    text = re.sub(r\"[^\\w\\sàáạảãâầấậẩẫăằắặẳẵèéẹẻẽêềếệểễìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữỳýỵỷỹđ]\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(preprocess_text(\"Ăn phở 50k\"))\n",
    "print(preprocess_text(\"đi grap 30k\"))\n",
    "print(preprocess_text(\"cf vs bạn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "with open('training_data.json', 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "print(f\"Total records: {len(raw_data)}\")\n",
    "print(f\"Sample: {raw_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data\n",
    "CATEGORIES = [\n",
    "    \"income\", \"food\", \"transportation\", \"entertainment\", \"shopping\",\n",
    "    \"health\", \"education\", \"utilities\", \"home\", \"personal\",\n",
    "    \"travel\", \"investment\", \"family\", \"houseware\", \"donation\", \"charity\", \"other\"\n",
    "]\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for record in raw_data:\n",
    "    text = record.get('text', '')\n",
    "    category = record.get('correctedCategory', record.get('category', ''))\n",
    "    \n",
    "    if text and category and category in CATEGORIES:\n",
    "        texts.append(preprocess_text(text))\n",
    "        labels.append(category)\n",
    "\n",
    "print(f\"Valid samples: {len(texts)}\")\n",
    "\n",
    "# Category distribution\n",
    "category_counts = Counter(labels)\n",
    "print(\"\\nCategory distribution:\")\n",
    "for cat, count in category_counts.most_common():\n",
    "    print(f\"  {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === DATASET SUMMARY TABLE ===\n\ndf = pd.DataFrame({'text': texts, 'category': labels})\ndf['word_count'] = df['text'].apply(lambda x: len(x.split()))\n\n# Summary table\nsummary = df.groupby('category').agg(\n    samples=('text', 'count'),\n    avg_words=('word_count', 'mean'),\n    min_words=('word_count', 'min'),\n    max_words=('word_count', 'max')\n).round(1)\n\nsummary['percent'] = (summary['samples'] / len(df) * 100).round(1)\nsummary = summary[['samples', 'percent', 'avg_words', 'min_words', 'max_words']]\nsummary.columns = ['Samples', '%', 'Avg Words', 'Min', 'Max']\nsummary = summary.sort_values('Samples', ascending=False)\n\nprint(f\"Total: {len(df)} samples, {len(category_counts)} categories\\n\")\nprint(summary.to_string())"
  },
  {
   "cell_type": "code",
   "source": "# Data Analysis - Kiểm tra imbalanced data\nprint(\"=== DATA QUALITY CHECK ===\\n\")\n\n# 1. Check imbalance ratio\nmax_count = max(category_counts.values())\nmin_count = min(category_counts.values())\nprint(f\"Imbalance ratio: {max_count/min_count:.1f}x\")\nprint(f\"Max category: {max(category_counts, key=category_counts.get)} ({max_count})\")\nprint(f\"Min category: {min(category_counts, key=category_counts.get)} ({min_count})\")\n\n# 2. Check text length distribution\ntext_lengths = [len(t.split()) for t in texts]\nprint(f\"\\nText length (words): mean={np.mean(text_lengths):.1f}, min={min(text_lengths)}, max={max(text_lengths)}\")\n\n# 3. Categories cần thêm data\nprint(\"\\nCategories cần thêm data (< 500 samples):\")\nfor cat, count in category_counts.items():\n    if count < 500:\n        print(f\"  {cat}: {count} (cần thêm ~{500-count})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "TFIDF_PARAMS = {\n",
    "    \"max_features\": 5000,\n",
    "    \"ngram_range\": (1, 3),\n",
    "    \"min_df\": 2,\n",
    "    \"max_df\": 0.95,\n",
    "    \"sublinear_tf\": True,\n",
    "}\n",
    "\n",
    "vectorizer = TfidfVectorizer(**TFIDF_PARAMS)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Number of features: {len(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "\n",
    "print(f\"Classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# So sánh nhiều models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodels = {\n    'SVM Linear': SVC(kernel='linear', probability=True, class_weight='balanced'),\n    'SVM RBF': SVC(kernel='rbf', probability=True, class_weight='balanced'),\n    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),\n    'Naive Bayes': MultinomialNB(),\n    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1),\n}\n\nprint(\"Comparing models with 5-fold CV:\\n\")\nresults = []\n\nfor name, clf in models.items():\n    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_weighted')\n    results.append({\n        'Model': name,\n        'Mean F1': scores.mean(),\n        'Std': scores.std()\n    })\n    print(f\"{name:20} F1: {scores.mean():.2%} (+/- {scores.std():.2%})\")\n\n# Visualize\nresults_df = pd.DataFrame(results).sort_values('Mean F1', ascending=True)\nplt.figure(figsize=(10, 5))\nplt.barh(results_df['Model'], results_df['Mean F1'], xerr=results_df['Std'], color='steelblue')\nplt.xlabel('F1 Score (weighted)')\nplt.title('Model Comparison')\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Hyperparameter Tuning với GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Tham số cần tìm kiếm\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'kernel': ['linear', 'rbf'],\n    'gamma': ['scale', 'auto'],  # Chỉ dùng cho rbf\n}\n\n# GridSearch với cross-validation 5-fold\ngrid_search = GridSearchCV(\n    SVC(probability=True, class_weight='balanced'),\n    param_grid,\n    cv=5,\n    scoring='f1_weighted',\n    n_jobs=-1,\n    verbose=1\n)\n\nprint(\"Searching best parameters...\")\ngrid_search.fit(X_train, y_train)\n\nprint(f\"\\nBest parameters: {grid_search.best_params_}\")\nprint(f\"Best CV score: {grid_search.best_score_:.2%}\")\n\n# Dùng model tốt nhất\nmodel = grid_search.best_estimator_"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Cross-validation: {cv_scores.mean():.2%} (+/- {cv_scores.std():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(14, 12))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "def predict(text):\n",
    "    processed = preprocess_text(text)\n",
    "    X_new = vectorizer.transform([processed])\n",
    "    proba = model.predict_proba(X_new)[0]\n",
    "    top_idx = np.argsort(proba)[::-1][:3]\n",
    "    \n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Preprocessed: {processed}\")\n",
    "    for idx in top_idx:\n",
    "        cat = label_encoder.inverse_transform([idx])[0]\n",
    "        conf = proba[idx]\n",
    "        print(f\"  {cat}: {conf:.2%}\")\n",
    "    print()\n",
    "\n",
    "# Test\n",
    "predict(\"ăn phở sáng 50k\")\n",
    "predict(\"đi grab về nhà\")\n",
    "predict(\"mua quần áo shopee\")\n",
    "predict(\"tiền điện tháng 12\")\n",
    "predict(\"lương tháng 1\")\n",
    "predict(\"cà phê với bạn\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# === EXPORT FOR THESIS/REPORT ===\n\nprint(\"=\" * 60)\nprint(\"THÔNG TIN CHO ĐỒ ÁN\")\nprint(\"=\" * 60)\n\n# 1. Dataset Overview\nprint(\"\\n1. TỔNG QUAN DATASET\")\nprint(\"-\" * 40)\nprint(f\"   Tổng số mẫu:     {len(df):,}\")\nprint(f\"   Số categories:   {len(category_counts)}\")\nprint(f\"   Ngôn ngữ:        Tiếng Việt\")\n\n# 2. Category Distribution Table\nprint(\"\\n2. PHÂN BỐ DỮ LIỆU THEO CATEGORY\")\nprint(\"-\" * 40)\nprint(summary.to_string())\n\n# 3. Preprocessing\nprint(\"\\n3. TIỀN XỬ LÝ VĂN BẢN\")\nprint(\"-\" * 40)\nprint(\"   - Unicode normalization (NFC)\")\nprint(\"   - Chuyển lowercase\")\nprint(\"   - Chuẩn hóa teencode (k→không, dc→được, cf→cafe, ...)\")\nprint(\"   - Sửa lỗi chính tả (grap→grab, shoppee→shopee, ...)\")\nprint(\"   - Loại bỏ ký tự đặc biệt, giữ tiếng Việt\")\n\n# 4. Feature Extraction\nprint(\"\\n4. TRÍCH XUẤT ĐẶC TRƯNG (TF-IDF)\")\nprint(\"-\" * 40)\nprint(f\"   N-gram range:    (1, 3)\")\nprint(f\"   Max features:    5,000\")\nprint(f\"   Min document freq: 2\")\nprint(f\"   Max document freq: 95%\")\nprint(f\"   Sublinear TF:    True\")\nprint(f\"   Số features thực tế: {X.shape[1]:,}\")\n\n# 5. Model Info\nprint(\"\\n5. MÔ HÌNH PHÂN LOẠI\")\nprint(\"-\" * 40)\nprint(f\"   Algorithm:       {type(model).__name__}\")\nif hasattr(model, 'kernel'):\n    print(f\"   Kernel:          {model.kernel}\")\nif hasattr(model, 'C'):\n    print(f\"   C:               {model.C}\")\nprint(f\"   Class weight:    balanced\")\n\n# 6. Results\nprint(\"\\n6. KẾT QUẢ\")\nprint(\"-\" * 40)\nprint(f\"   Train/Test split: 80/20\")\nprint(f\"   Accuracy:        {accuracy:.2%}\")\nprint(f\"   Cross-validation: {cv_scores.mean():.2%} (+/- {cv_scores.std():.2%})\")\n\n# 7. Classification Report\nprint(\"\\n7. CLASSIFICATION REPORT\")\nprint(\"-\" * 40)\nprint(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features per category\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Top 10 features per category:\")\n",
    "for i, category in enumerate(label_encoder.classes_):\n",
    "    # Get indices of samples in this category\n",
    "    cat_mask = (y == i)\n",
    "    if cat_mask.sum() == 0:\n",
    "        continue\n",
    "    \n",
    "    # Mean TF-IDF for this category\n",
    "    cat_tfidf = X[cat_mask].mean(axis=0).A1\n",
    "    top_indices = cat_tfidf.argsort()[::-1][:10]\n",
    "    top_features = [(feature_names[idx], cat_tfidf[idx]) for idx in top_indices]\n",
    "    \n",
    "    print(f\"\\n{category}:\")\n",
    "    for feat, score in top_features:\n",
    "        print(f\"  {feat}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model (optional - download to local)\n",
    "import joblib\n",
    "\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
    "joblib.dump(model, 'svm_classifier.joblib')\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "# Download\n",
    "files.download('tfidf_vectorizer.joblib')\n",
    "files.download('svm_classifier.joblib')\n",
    "files.download('label_encoder.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}